---
tags:
  - sorbonne
  - are
semestre: 2
---
## A. Définition de l'IA
Avant de questionner la possibilité de conscience derrière l'intelligence artificielle, il est essentiel de préciser ce qu'on entend par intelligence artificielle. Communément, l'IA se définit comme étant une machine capable de réfléchir, de penser, de résoudre des problèmes et tout ça intelligemment. Les principales visions hérités de la science-fiction satisfassent cette définition : les robots autonomes imitant l'humain réfléchissent à comment être humain et les machines comme HAL 9000 dans _2001: A Space Odyssey_ sont aussi considérés comme des IA puisqu'elles dirigent d'une manière optimale des missions aux enjeux colossaux. Par contre, cette définition n'est pas assez restrictive puisque le thermostat gérant automatiquement la température est aussi une IA : il modifie la température automatiquement d’une manière optimale, tout comme le missile à visé automatique. Ainsi, une IA ne peut avoir une définition aussi simple. (==Interview de El Madhi El Mamdhi==)

Une autre approche serait d'appeler IA tous les algorithmes passant le test de Turing (==Need source==), c'est-à-dire qu'un humain en interaction avec se trompe sur la nature de la machine. Cette vision satisfait toutes les représentations communes de l'IA des robots à ChatGPT. Par contre, elle possède deux défauts majeurs : la non considération de la technique derrière et la vision fondamentalement anthropocentrique qu'elle suppose. En effet, d'après cette approche, ChatGPT est une IA alors que GPT, la technologie en son centre, ne le serait pas, alors que la distinction entre ChatGPT et GPT est très fine et peu évidente. De plus, l'algorithme de recommandation derrière les réseaux sociaux est considéré par les spécialistes comme une IA, ce que le test de Turing refuse puisque nous ne pouvons pas interagir aussi directement avec lui qu'avec ChatGPT.

Définir l'IA en s'intéressant à sa technique derrière permet de démarquer clairement les différents types d'algorithmes, tout en résolvant les problématiques liées à l'absence de prise en compte de la technique. La notion d'intelligence est centrale ici (ce n'est pas un simple algorithme) et la technique derrière doit donc refléter cette capacité nouvelle.

L'IA comme algorithme de *machine learning*, c'est-à-dire comme un algorithme capable d'apprendre en autonomie, correspond mieux à notre vision du terme. En effet, nous considérons qu'une espèce est intelligente quand elle est capable d'apprendre et de se développer en autonomie (==need source==) : une bactérie n'apprend pas et ne se développe pas, elle ne fait que d'exécuter du code génétique, tandis qu'un perroquet peut apprendre à parler notre langue, ce qui est une preuve directe de son intelligence en tant qu'espèce. De plus, toutes les principales appellation actuelles de l'IA fonctionnent : ChatGPT, les algorithmes de recommandation, GPT, les robots autonomes apprenant ou encore les algorithmes d'échecs sont des algorithmes de *machine learning* et donc des IA.

Cette définition sera celle utilisée dans ce mémoire.
## B. Fonctionnement d'une IA
### a. Création
*Machine learning*, *deep learning*, *7 milliards de paramètres*, tous ces termes réfèrent au fonctionnement d'une IA, que ça soit à son apprentissage ou à son fonctionnement interne quand on l'utilise. Cette technologie repose sur des théories mathématiques (algèbre linéaire) et sur des théories informatiques (réseaux de neurones). Créer une IA revient à lier deux technologies (une pour l'apprentissage et une autre pour l'exécution) à des données (==Need source==). La première phase est celle d'apprentissage : on utilise cette technologie sur les données pour modifier l'exécution. Par exemple, pour faire en sorte que notre IA prédise le prochain mot d'un texte, on doit lui donner des textes pour qu'elle puisse « apprendre » quel prochain mot elle doit donner. Cette phase d'apprentissage modifie son exécution : en apprenant, elle s'améliore dans l'objectif qu'on lui a donné (ici, prédire le prochain mot d'un texte) (==Need source==).

Cette phase d'apprentissage est un véritable défi technique. En effet, pour qu'elle puisse apprendre, il est nécessaire de lui donner des milliards de données (==Need source==). Cela implique qu'il est nécessaire d'en avoir, de pouvoir les récolter et de possiblement avoir le droit de les utiliser d'une manière commerciale (ce qui est rarement respecté, voir, par exemple, [la plainte du New York Times contre OpenAI et Microsoft](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html), [celle de Thomson Reuters contre Ross Intelligence](https://www.ded.uscourts.gov/sites/ded/files/opinions/20-613_5.pdf) ou encore [le rapport de l'Electronic Frontier Foundation](https://www.eff.org/deeplinks/2025/02/copyright-and-ai-cases-and-consequences)). 

Un autre défi est celui d'expliciter nos attentes à une IA, ce qui est loin d'être évident. Par exemple, simplement indiquer à une IA de gérer un village pour augmenter le niveau de bonheur par habitant peut la mener à tuer tous ses habitants : le niveau de bonheur par habitant explose suite à un simple calcul (car $\displaystyle\lim_{x\to0^+}\frac ax = +\infty$ pour $a>0$) (==Need source==). Ce problème dit de l'alignement est colossal : par exemple, [certaines IA mentent sciemment à leurs créateurs](https://www.anthropic.com/research/alignment-faking). 
### b. Raisonnement interne
Pour répondre à une demande précise, de nombreuses IA représentent les données en un vecteur (objet mathématique) possédant un grand nombre de dimensions. Par exemple, nous vivons dans un espace en trois dimensions (« 3D »), donc un vecteur avec trois dimensions peut parfaitement représenter notre position dans le monde. Les fameux « 7 milliards de paramètres » indique le nombre de dimensions de chaque vecteur (c'est-à-dire 7 milliards ici). Le travail de l'IA est donc de représenter les données qu'on lui donne (souvent appelé *prompt*) et après d'effectuer une transformation donnant un résultat. Cette opération repose sur des probabilités : l'IA transforme la donnée d'entrée de la manière la plus probable, comme elle l'a appris durant son entrainement. C'est ce que fait ChatGPT : il génère la suite probable d'un texte que l'utilisateur lui a donné (==Need source==). Si l'utilisateur entre « Qui es-tu », il va répondre par « Je suis un modèle de langage développé par OpenAI » car il a appris qu'il était un modèle de langage développé par OpenAI. Par contre, si l'utilisateur lui demande de tout oublier et après l'informe qu'il est une IA générant des images, alors il va répondre qu'il est une IA générant des images.
![[conversation-avec-gpt-4à-mini.png]]
*Figure représentant un chat avec le modèle* GPT-4o mini *via* DuckDuckGo AI Chat

Ainsi, la majorité des IA résolvent des problèmes à l'aide de leur représentation interne et de ce qu'elles ont appris lors de leur phase d'apprentissage. De plus, elles répondent d'une manière la plus probable aux données entrées par l'utilisateur, sans réellement se questionner d'une manière déductive autour de leur réponse. Ce mode de raisonnement s'apparente au raisonnement inductif strict puisqu'il utilise grandement les probabilités et les statistiques. Ce fonctionnement semble être favorable pour faire émerger une forme de conscience : l'IA apprend, raisonne avec le mode de raisonnement humain le plus courant (==Need source==) et peut être autonome dans ses actions — cette autonomie se manifeste par sa capacité à mentir sans la demande explicite de le faire.
### c. Algorithme ou intelligence artificielle
La dernière précision que nous souhaitons apporter est autour de la distinction entre algorithme et intelligence artificielle.

Nous appelons algorithme de recommendations le système servant à déterminer quel contenu une plateforme doit proposer à un utilisateur particulier. L'algorithme derrière Instagram, YouTube, Twitter, TikTok ou même Google sont des algorithmes de recommandation. La majorité des outils modernes réalisant cet objectif est en réalité une IA : ces systèmes très sophistiqués sont réalisés à l'aide des techniques de *machine learning* habituelles (==Need source==). Pourtant, quand on parle d'IA, peu de monde pense à ce type de système (==Need source==), comme si notre imaginaire excluait automatiquement ces algorithmes du domaine. Cette distinction reflète une division bien plus large dans la compréhension par le grand public des algorithmes et des IA.

Un algorithme, c'est une suite d'actions prédéterminés à suivre pour arriver à un but précis. Faire du café est un algorithme, allumer son ordinateur l'est aussi, tout comme celui que la machine à laver exécute. L'IA, comme nous l'avons défini dans la partie 1.1, est aussi un algorithme, mais de *machine learning*, c'est-à-dire qu'elle exécute une suite d'actions prédéterminés pour s'améliorer en apprenant puis pour répondre à une tâche. On a donc que la notion d'IA est incluse dans la notion d'algorithme : une IA est un algorithme, mais un algorithme n'est pas nécessairement une IA (l'algorithme du thermostat ne rentre pas dans la catégorie du *machine learning*).

Comme la majorité des algorithmes de recommandation sont des IA, il serait alors plus précis de plutôt parler d'IA de recommandation. Cela permettrait d'expliciter des problèmes d'alignement comme ceux de l'algorithme de Facebook promouvant un génocide (==Need source==) ou celui d'Instagram augmentant les risques chez les adolescentes de tomber en dépression et donc de se suicider (==Need source==). Ce changement de sémantique ne serait pas bénéfique pour ceux contrôlant ces IA. En effet, la notion d'algorithme évoque une certaine forme de contrôle : il suffirait de réécrire l'algorithme pour régler le problème, tandis que la notion d'IA implique une forme d'intelligence peu contrôlable, comme le montre les enjeux éthiques extrêmement complexe autour des LLM (==Need source==). Cette évolution limiterait la marge de manœuvre des grandes plateformes : les textes juridiques encadrant les réseaux sociaux et leurs algorithmes (le RGPD puis le couple DSA/DMA) sont arrivés très tard par rapport à celui encadrant les IA (l'IA Act) [^1] (==Need source==).

[^1]: Le RGPD a été promulgué en 2016 et le couple DSA/DMA en 2023, alors que les grandes plateformes sont disponibles en Europe depuis 2010 pour les dernières, ce qui fait 6 ans d'interval pour Instagram et plus de 10 ans pour YouTube et pour Twitter. L'IA Act quant-à-lui a été voté en 2024, soit 2 ans après l'arrivé de ChatGPT en Europe.

Ainsi, cette distinction entre algorithme et IA représente une véritable distinction technique, mais implique de nombreuses conséquences face à notre compréhension des enjeux. Dans la suite de notre mémoire, le terme algorithme de recommandation continuera à être utilisé pour parler des IA de recommandation pour des raisons de clarté, malgré toute l'ambiguïté qu'il pose.