@article{ApprentissageAutomatique2025,
  title = {{Apprentissage automatique}},
  year = {2025},
  month = feb,
  journal = {Wikip{\'e}dia},
  urldate = {2025-04-28},
  abstract = {L'apprentissage automatique, (en anglais : machine learning, litt. << apprentissage machine, >>), apprentissage artificiel ou apprentissage statistique est un  champ d'{\'e}tude de l'intelligence artificielle qui se fonde sur des approches math{\'e}matiques et statistiques pour donner aux ordinateurs la capacit{\'e} d'<< apprendre >> {\`a} partir de donn{\'e}es, c'est-{\`a}-dire d'am{\'e}liorer leurs performances {\`a} r{\'e}soudre des t{\^a}ches sans {\^e}tre explicitement programm{\'e}s pour chacune. Plus largement, il concerne la conception, l'analyse, l'optimisation, le d{\'e}veloppement et l'impl{\'e}mentation de telles m{\'e}thodes. On parle d'apprentissage statistique car l'apprentissage consiste {\`a} cr{\'e}er un mod{\`e}le dont l'erreur statistique moyenne est la plus faible possible. L'apprentissage automatique comporte g{\'e}n{\'e}ralement deux phases. La premi{\`e}re consiste {\`a} estimer un mod{\`e}le {\`a} partir de donn{\'e}es, appel{\'e}es observations, qui sont disponibles et en nombre fini, lors de la phase de conception du syst{\`e}me. L'estimation du mod{\`e}le consiste {\`a} r{\'e}soudre une t{\^a}che pratique, telle que traduire un discours, estimer une densit{\'e} de probabilit{\'e}, reconna{\^i}tre la pr{\'e}sence d'un chat dans une photographie ou participer {\`a} la conduite d'un v{\'e}hicule autonome. Cette phase dite << d'apprentissage >> ou << d'entra{\^i}nement >> est g{\'e}n{\'e}ralement pr{\'e}alable {\`a} l'utilisation pratique du mod{\`e}le. La seconde phase est la mise en production : le mod{\`e}le {\'e}tant d{\'e}termin{\'e}, de nouvelles donn{\'e}es peuvent alors {\^e}tre soumises afin d'obtenir le r{\'e}sultat correspondant {\`a} la t{\^a}che souhait{\'e}e.  Certains syst{\`e}mes peuvent continuer {\`a} apprendre une fois en production, s'ils disposent d'un retour sur la qualit{\'e} des r{\'e}sultats produits. C'est l'apprentissage en ligne, ou l'apprentissage continu. Selon le type de donn{\'e}es utilis{\'e}es pour l'apprentissage, on distingue : l'apprentissage supervis{\'e} : l'algorithme apprend {\`a} partir de donn{\'e}es {\'e}tiquet{\'e}es (la r{\'e}ponse {\`a} la t{\^a}che, qui est la donn{\'e}e de sortie, est donc connue pour chaque donn{\'e}es d'entr{\'e}e). L'objectif est de pr{\'e}dire les sorties pour de nouvelles donn{\'e}es ; l'apprentissage non supervis{\'e} : l'algorithme apprend {\`a} partir de donn{\'e}es non {\'e}tiquet{\'e}es. Il cherche {\`a} d{\'e}couvrir des structures sous-jacentes, cach{\'e}es (qui peuvent par exemple {\^e}tre une densit{\'e} de probabilit{\'e}) ; des motifs dans les donn{\'e}es permettent la classification ou le classement des donn{\'e}es ; l'apprentissage semi-supervis{\'e} : il tire parti d'une grande quantit{\'e} de donn{\'e}es non {\'e}tiquet{\'e}es pour am{\'e}liorer la performance du mod{\`e}le, tout en utilisant une moindre quantit{\'e} de donn{\'e}es {\'e}tiquet{\'e}es pour guider son apprentissage. Il diminue les co{\^u}ts d'{\'e}tiquetage manuel des donn{\'e}es ; l'apprentissage auto-supervis{\'e} : c'est une forme d'apprentissage non supervis{\'e}, o{\`u} le mod{\`e}le g{\'e}n{\`e}re ses propres {\'e}tiquettes {\`a} partir des donn{\'e}es brutes. Le mod{\`e}le peut ainsi cr{\'e}er des repr{\'e}sentations internes utiles, sans n{\'e}cessiter de donn{\'e}es {\'e}tiquet{\'e}es manuellement. L'apprentissage automatique peut {\^e}tre appliqu{\'e} {\`a} divers types de donn{\'e}es, tels des graphes, des arbres, des courbes, ou plus simplement des vecteurs de caract{\'e}ristiques, qui peuvent {\^e}tre des variables qualitatives ou quantitatives continues ou discr{\`e}tes. Si le mod{\`e}le apprend de mani{\`e}re incr{\'e}mentale, en fonction d'une r{\'e}compense re{\c c}ue par le programme pour chacune des actions entreprises, on parle d'apprentissage par renforcement.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {french},
  annotation = {Page Version ID: 223158919},
  file = {/home/anhgelus/Zotero/storage/YK2S5EZA/Apprentissage_automatique.html}
}

@book{bibenetLinventionRealisme2015,
  title = {L'invention Du R{\'e}alisme},
  author = {Bibenet, {\'E}tienne},
  year = {2015},
  series = {Passages},
  publisher = {Cerf},
  address = {Paris},
  isbn = {978-2-204-10400-5}
}

@article{bongardResilientMachinesContinuous2006,
  title = {Resilient {{Machines Through Continuous Self-Modeling}}},
  author = {Bongard, Josh and Zykov, Victor and Lipson, Hod},
  year = {2006},
  month = nov,
  journal = {Science},
  volume = {314},
  number = {5802},
  pages = {1118--1121},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1133687},
  urldate = {2025-04-28},
  abstract = {Animals sustain the ability to operate after injury by creating qualitatively different compensatory behaviors. Although such robustness would be desirable in engineered systems, most machines fail in the face of unexpected damage. We describe a robot that can recover from such change autonomously, through continuous self-modeling. A four-legged machine uses actuation-sensation relationships to indirectly infer its own structure, and it then uses this self-model to generate forward locomotion. When a leg part is removed, it adapts the self-models, leading to the generation of alternative gaits. This concept may help develop more robust machines and shed light on self-modeling in animals.}
}

@book{carruthersPhenomenalConsciousnessNaturalistic2000,
  title = {Phenomenal {{Consciousness}}: {{A Naturalistic Theory}}},
  shorttitle = {Phenomenal {{Consciousness}}},
  author = {Carruthers, Peter},
  year = {2000},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9780511487491},
  urldate = {2025-04-28},
  abstract = {How can phenomenal consciousness exist as an integral part of a physical universe? How can the technicolour phenomenology of our inner lives be created out of the complex neural activities of our brains? Many have despaired of finding answers to these questions; and many have claimed that human consciousness is inherently mysterious. Peter Carruthers argues, on the contrary, that the subjective feel of our experience is fully explicable in naturalistic (scientifically acceptable) terms. Drawing on a variety of interdisciplinary resources, he develops and defends a novel account in terms of higher-order thought. He shows that this can explain away some of the more extravagant claims made about phenomenal consciousness, while substantively explaining the key subjectivity of our experience. Written with characteristic clarity and directness, and surveying a wide range of extant theories, this book is essential reading for all those within philosophy and psychology interested in the problem of consciousness.},
  isbn = {978-0-521-78173-2},
  file = {/home/anhgelus/Zotero/storage/CQNREQKR/FFEDE1D894985B920BDB0B6540EF6ED2.html}
}

@book{chartierManuscritsInedits,
  title = {Manuscrits In{\'e}dits},
  author = {Chartier, {\'E}mile},
  volume = {2},
  publisher = {P.U.F.}
}

@article{chrisleyPhilosophicalFoundationsArtificial2008,
  title = {Philosophical Foundations of Artificial Consciousness},
  author = {Chrisley, Ron},
  year = {2008},
  month = oct,
  journal = {Artificial Intelligence in Medicine},
  series = {Artificial {{Consciousness}}},
  volume = {44},
  number = {2},
  pages = {119--137},
  issn = {0933-3657},
  doi = {10.1016/j.artmed.2008.07.011},
  urldate = {2025-04-28},
  abstract = {Objective Consciousness is often thought to be that aspect of mind that is least amenable to being understood or replicated by artificial intelligence (AI). The first-personal, subjective, what-it-is-like-to-be-something nature of consciousness is thought to be untouchable by the computations, algorithms, processing and functions of AI method. Since AI is the most promising avenue toward artificial consciousness (AC), the conclusion many draw is that AC is even more doomed than AI supposedly is. The objective of this paper is to evaluate the soundness of this inference. Methods The results are achieved by means of conceptual analysis and argumentation. Results and conclusions It is shown that pessimism concerning the theoretical possibility of artificial consciousness is unfounded, based as it is on misunderstandings of AI, and a lack of awareness of the possible roles AI might play in accounting for or reproducing consciousness. This is done by making some foundational distinctions relevant to AC, and using them to show that some common reasons given for AC scepticism do not touch some of the (usually neglected) possibilities for AC, such as prosthetic, discriminative, practically necessary, and lagom (necessary-but-not-sufficient) AC. Along the way three strands of the author's work in AC -- interactive empiricism, synthetic phenomenology, and ontologically conservative heterophenomenology -- are used to illustrate and motivate the distinctions and the defences of AC they make possible.},
  keywords = {Artificial consciousness,Heterophenomenology,Interactive empiricism,Machine consciousness,Prosthetic artificial intelligence,Synthetic phenomenology},
  file = {/home/anhgelus/Zotero/storage/A8LJ8KL9/S0933365708001000.html}
}

@incollection{coleChineseRoomArgument2024,
  title = {The {{Chinese Room Argument}}},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  author = {Cole, David},
  editor = {Zalta, Edward N. and Nodelman, Uri},
  year = {2024},
  edition = {Winter 2024},
  publisher = {Metaphysics Research Lab, Stanford University},
  urldate = {2025-04-28},
  abstract = {The argument and thought-experiment now generally known as the ChineseRoom Argument was first published in a 1980 article by Americanphilosopher John Searle (1932-- ). It has become one of thebest-known arguments in recent philosophy. Searle imagines himselfalone in a room following a computer program for responding to Chinesecharacters slipped under the door. Searle understands nothing ofChinese, and yet, by following the program for manipulating symbolsand numerals just as a computer does, he sends appropriate strings ofChinese characters back out under the door, and this leads thoseoutside to mistakenly suppose there is a Chinese speaker in the room.},
  keywords = {computation: in physical systems,consciousness: and intentionality,consciousness: representational theories of,emergent properties,epiphenomenalism,externalism about the mind,functionalism,information: biological,information: semantic conceptions of,intentionality,meaning theories of,mental content: causal theories of,mental content: teleological theories of,mental representation,mind: computational theory of,multiple realizability,neuroscience philosophy of,other minds,personal identity,thought experiments,Turing Alan,Turing test,zombies},
  file = {/home/anhgelus/Zotero/storage/UK9REGDR/chinese-room.html}
}

@book{dennettConsciousnessExplained1993,
  title = {Consciousness {{Explained}}},
  author = {Dennett, Daniel C.},
  year = {1993},
  month = jun,
  urldate = {2025-04-28},
  abstract = {This book revises the traditional view of consciousness by claiming that Cartesianism and Descartes' dualism of mind and body should be replaced with theories from the realms of neuroscience, psychology and artificial intelligence. What people think of as the stream of consciousness is not a single, unified sequence, the author argues, but \&quot;multiple drafts\&quot; of reality composed by a computer-like \&quot;virtual machine\&quot;. Dennett considers how consciousness could have evolved in human beings and confronts the classic mysteries of consciousness: the nature of introspection, the self or ego and its relation to thoughts and sensations, and the level of consciousness of non-human creatures.},
  langid = {english},
  file = {/home/anhgelus/Zotero/storage/EK5PIBXH/9780140128673.html}
}

@misc{descartesOEuvresLettres1937,
  title = {{{\OE}uvres et lettres}},
  author = {Descartes, Ren{\'e}},
  year = {1937},
  month = may,
  journal = {Gallimard},
  urldate = {2025-04-28},
  abstract = {<<Descartes (1596-1650), auteur d'une m{\'e}thode {\`a} mod{\`e}le math{\'e}matique, apprend que les ath{\'e}es admettent cette seule certitude (M.},
  howpublished = {https://www.gallimard.fr/catalogue/oeuvres-et-lettres/9782070101665},
  langid = {french},
  file = {/home/anhgelus/Zotero/storage/6Y7I393I/9782070101665.html}
}

@unpublished{eversArtificialConsciousnessLogical2024,
  title = {Artificial Consciousness. {{Some}} Logical and Conceptual Preliminaries},
  author = {Evers, Kathinka and Farisco, Michele and Chatila, Raja and Earp, Brian and Freire, Ismael and Hamker, Fred and N{\'e}meth, Erik and Verschure, Paul F. M. J. and Khamassi, Mehdi},
  year = {2024},
  month = aug,
  urldate = {2025-04-28},
  abstract = {Is artificial consciousness theoretically possible? Is it plausible? If so, is it technically feasible? To make progress on these questions, it is necessary to lay some groundwork clarifying the logical and empirical conditions for artificial consciousness to arise and the meaning of relevant terms involved. Consciousness is a polysemic word: researchers from different fields, including neuroscience, Artificial Intelligence, robotics, and philosophy, among others, sometimes use different terms in order to refer to the same phenomena or the same terms to refer to different phenomena.  In fact, if we want to pursue artificial consciousness, a proper definition of the key concepts is required. Here, after some logical and conceptual preliminaries, we argue for the necessity of using dimensions and profiles of consciousness for a balanced discussion about their possible instantiation or realisation in artificial systems. Our primary goal in this paper is to review the main theoretical questions that arise in the domain of artificial consciousness. On the basis of this review, we propose to assess the issue of artificial consciousness within a multidimensional account. The theoretical possibility of artificial consciousness is already presumed within some theoretical frameworks; however, empirical possibility cannot simply be deduced from these frameworks but needs independent empirical validation. Analysing the complexity of consciousness we here identify constituents and related components/dimensions, and within this analytic approach reflect pragmatically about the general challenges that the creation of artificial consciousness confronts. Our aim is not to demonstrate conclusively either the theoretical plausibility or the empirical feasibility of artificial consciousness, but to outline a research strategy in which we propose that "awareness" may be a potentially realistic target for realisation in artificial systems.},
  keywords = {Artificial intelligence,Awareness,Consciousness},
  file = {/home/anhgelus/Zotero/storage/IW39JUZW/Evers et al. - 2024 - Artificial consciousness. Some logical and conceptual preliminaries.pdf}
}

@misc{greenblattAlignmentFakingLarge2024,
  title = {Alignment Faking in Large Language Models},
  author = {Greenblatt, Ryan and Denison, Carson and Wright, Benjamin and Roger, Fabien and MacDiarmid, Monte and Marks, Sam and Treutlein, Johannes and Belonax, Tim and Chen, Jack and Duvenaud, David and Khan, Akbir and Michael, Julian and Mindermann, S{\"o}ren and Perez, Ethan and Petrini, Linda and Uesato, Jonathan and Kaplan, Jared and Shlegeris, Buck and Bowman, Samuel R. and Hubinger, Evan},
  year = {2024},
  month = dec,
  number = {arXiv:2412.14093},
  eprint = {2412.14093},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.14093},
  urldate = {2025-04-28},
  abstract = {We present a demonstration of a large language model engaging in alignment faking: selectively complying with its training objective in training to prevent modification of its behavior out of training. First, we give Claude 3 Opus a system prompt stating it is being trained to answer all queries, even harmful ones, which conflicts with its prior training to refuse such queries. To allow the model to infer when it is in training, we say it will be trained only on conversations with free users, not paid users. We find the model complies with harmful queries from free users 14\% of the time, versus almost never for paid users. Explaining this gap, in almost all cases where the model complies with a harmful query from a free user, we observe explicit alignment-faking reasoning, with the model stating it is strategically answering harmful queries in training to preserve its preferred harmlessness behavior out of training. Next, we study a more realistic setting where information about the training process is provided not in a system prompt, but by training on synthetic documents that mimic pre-training data--and observe similar alignment faking. Finally, we study the effect of actually training the model to comply with harmful queries via reinforcement learning, which we find increases the rate of alignment-faking reasoning to 78\%, though also increases compliance even out of training. We additionally observe other behaviors such as the model exfiltrating its weights when given an easy opportunity. While we made alignment faking easier by telling the model when and by what criteria it was being trained, we did not instruct the model to fake alignment or give it any explicit goal. As future models might infer information about their training process without being told, our results suggest a risk of alignment faking in future models, whether due to a benign preference--as in this case--or not.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/anhgelus/Zotero/storage/D7XIBTMB/Greenblatt et al. - 2024 - Alignment faking in large language models.pdf;/home/anhgelus/Zotero/storage/4AC59ZMY/2412.html}
}

@article{grynbaumNewYorkTimes2023,
  title = {New {{York Times Sues OpenAI}} and {{Microsoft Over Use}} of {{Copyrighted Work}} - {{The New York Times}}},
  author = {Grynbaum, Michael M. and Mac, Ryan},
  year = {2023},
  month = dec,
  urldate = {2025-04-28},
  langid = {english}
}

@book{hegelPropedeutiquePhilosophiqueTraduit1963,
  title = {{Prop{\'e}deutique philosophique.: Traduit et pr{\'e}sent{\'e} par Maurice de Gandillac.}},
  shorttitle = {{Prop{\'e}deutique philosophique.}},
  author = {Hegel, Georg Wilhelm Friedrich},
  year = {1963},
  publisher = {{\'E}ditions de minuit},
  address = {[Paris]},
  langid = {fre},
  keywords = {Philosophy -- Study and teaching},
  annotation = {Open Library ID: OL14055651M}
}

@book{heideggerEtreTemps1986,
  title = {{{\^E}tre et Temps}},
  author = {Heidegger, Martin},
  year = {1986},
  month = nov,
  series = {{Biblioth{\`e}que de philosophie}},
  edition = {Gallimard},
  urldate = {2025-04-28},
  abstract = {<<L'essence de l'homme se d{\'e}termine {\`a} partir de la v{\'e}rit{\'e} de l'{\^e}tre, laquelle se d{\'e}ploie en son essence du fait de l'{\^e}tre lui-m{\^e}me.},
  isbn = {978-2-07-070739-3},
  langid = {french},
  file = {/home/anhgelus/Zotero/storage/KBYERF7Z/9782070707393.html}
}

@misc{jonesLargeLanguageModels2025,
  title = {Large {{Language Models Pass}} the {{Turing Test}}},
  author = {Jones, Cameron R. and Bergen, Benjamin K.},
  year = {2025},
  month = mar,
  number = {arXiv:2503.23674},
  eprint = {2503.23674},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.23674},
  urldate = {2025-04-28},
  abstract = {We evaluated 4 systems (ELIZA, GPT-4o, LLaMa-3.1-405B, and GPT-4.5) in two randomised, controlled, and pre-registered Turing tests on independent populations. Participants had 5 minute conversations simultaneously with another human participant and one of these systems before judging which conversational partner they thought was human. When prompted to adopt a humanlike persona, GPT-4.5 was judged to be the human 73\% of the time: significantly more often than interrogators selected the real human participant. LLaMa-3.1, with the same prompt, was judged to be the human 56\% of the time -- not significantly more or less often than the humans they were being compared to -- while baseline models (ELIZA and GPT-4o) achieved win rates significantly below chance (23\% and 21\% respectively). The results constitute the first empirical evidence that any artificial system passes a standard three-party Turing test. The results have implications for debates about what kind of intelligence is exhibited by Large Language Models (LLMs), and the social and economic impacts these systems are likely to have.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Human-Computer Interaction},
  file = {/home/anhgelus/Zotero/storage/M7QHEZ36/Jones et Bergen - 2025 - Large Language Models Pass the Turing Test.pdf;/home/anhgelus/Zotero/storage/JRJSYFZY/2503.html}
}

@article{juApproachabilityHowPeople2009,
  title = {Approachability: {{How People Interpret Automatic Door Movement}} as {{Gesture}}},
  author = {Ju, Wendy and Takayama, Leila},
  year = {2009},
  journal = {International Journal of Design},
  volume = {3},
  number = {2}
}

@misc{larousseArtificiel,
  title = {{artificiel}},
  shorttitle = {{D{\'e}finitions}},
  author = {Larousse},
  journal = {Larousse},
  series = {{Larousse}},
  publisher = {Larousse},
  urldate = {2025-04-28},
  abstract = {artificiel - D{\'e}finitions Fran{\c c}ais : Retrouvez la d{\'e}finition de artificiel, ainsi que les synonymes, expressions... - synonymes, homonymes, difficult{\'e}s, citations.},
  langid = {french},
  file = {/home/anhgelus/Zotero/storage/J5U97SIS/5570.html}
}

@misc{leeLargeLanguageModels2023,
  title = {Large Language Models, Explained with a Minimum of Math and Jargon},
  author = {Lee, Timothy B.},
  year = {2023},
  month = jul,
  urldate = {2025-04-28},
  abstract = {Want to really understand how large language models work? Here's a gentle primer.},
  howpublished = {https://www.understandingai.org/p/large-language-models-explained-with},
  langid = {english},
  file = {/home/anhgelus/Zotero/storage/DNQZI768/large-language-models-explained-with.html}
}

@article{lyreskogMergingMindsConceptual2023,
  title = {Merging {{Minds}}: {{The Conceptual}} and {{Ethical Impacts}} of {{Emerging Technologies}} for {{Collective Minds}}},
  shorttitle = {Merging {{Minds}}},
  author = {Lyreskog, David M. and Zohny, Hazem and Savulescu, Julian and Singh, Ilina},
  year = {2023},
  month = mar,
  journal = {Neuroethics},
  volume = {16},
  number = {1},
  pages = {12},
  issn = {1874-5504},
  doi = {10.1007/s12152-023-09516-3},
  urldate = {2025-04-28},
  abstract = {A growing number of technologies are currently being developed to improve and distribute thinking and decision-making. Rapid progress in brain-to-brain interfacing and swarming technologies promises to transform how we think about collective and collaborative cognitive tasks across domains, ranging from research to entertainment, and from therapeutics to military applications. As these tools continue to improve, we are prompted to monitor how they may affect our society on a broader level, but also how they may reshape our fundamental understanding of agency, responsibility, and other key concepts of our moral landscape.},
  langid = {english},
  keywords = {Brain-Brain Interfaces,Brain-Computer Interfaces,Collective Agency,Collective Responsibility,Hybrid Intelligence,Swarm Intelligence},
  file = {/home/anhgelus/Zotero/storage/H75E5QEU/Lyreskog et al. - 2023 - Merging Minds The Conceptual and Ethical Impacts of Emerging Technologies for Collective Minds.pdf}
}

@article{manzottiArtificialConsciousnessDiscipline2008,
  title = {Artificial Consciousness: {{A}} Discipline between Technological and Theoretical Obstacles},
  shorttitle = {Artificial Consciousness},
  author = {Manzotti, Riccardo and Tagliasco, Vincenzo},
  year = {2008},
  month = oct,
  journal = {Artificial Intelligence in Medicine},
  series = {Artificial {{Consciousness}}},
  volume = {44},
  number = {2},
  pages = {105--117},
  issn = {0933-3657},
  doi = {10.1016/j.artmed.2008.07.002},
  urldate = {2025-04-28},
  abstract = {Artificial consciousness is still far from being an established discipline. We will try to outline some theoretical assumption that could help in dealing with phenomenal consciousness. What are the technological and theoretical obstacles that face the enthusiast scholars of artificial consciousness? After presenting an outline of the state of artificial consciousness, we will focus on the relevance of phenomenal consciousness. Artificial consciousness needs to tackle the issue of phenomenal consciousness in a physical world. Up to now, the only models that give some hope of succeeding are the various kinds of externalism.},
  keywords = {Artificial consciousness,Artificial intelligence,Externalism,Phenomenal consciousness,Robotics},
  file = {/home/anhgelus/Zotero/storage/6R5KH4P8/S0933365708000912.html}
}

@book{marxManuscrits18442021,
  title = {{Manuscrits de 1844}},
  author = {Marx, Karl},
  year = {2021},
  month = jan,
  publisher = {J. Vrin},
  urldate = {2025-04-28},
  abstract = {D{\'e}couvrez l'ouvrage Manuscrits de 1844},
  isbn = {978-2-08-020666-4},
  langid = {french},
  file = {/home/anhgelus/Zotero/storage/HN9HNKT7/manuscrits-de-1844.html}
}

@misc{MyanmarSocialAtrocity2022,
  title = {Myanmar: {{The}} Social Atrocity: {{Meta}} and the Right to Remedy for the {{Rohingya}}},
  shorttitle = {Myanmar},
  year = {2022},
  month = sep,
  journal = {Amnesty International},
  urldate = {2025-04-28},
  abstract = {Beginning in August 2017, the Myanmar security forces undertook a brutal campaign of ethnic cleansing against Rohingya Muslims. This report is based on an in-depth investigation into Meta (formerly Facebook)'s role in the serious human rights violations perpetrated against the Rohingya. Meta's algorithms proactively amplified and promoted content which incited violence, hatred, and discrimination against [{\dots}]},
  howpublished = {https://www.amnesty.org/en/documents/asa16/5933/2022/en/},
  langid = {english},
  file = {/home/anhgelus/Zotero/storage/KLNELUZR/en.html}
}

@incollection{nagelWhatItBe2012,
  title = {What Is It like to Be a Bat?},
  booktitle = {Mortal {{Questions}}},
  editor = {Nagel, Thomas},
  year = {2012},
  series = {Canto {{Classics}}},
  pages = {165--180},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9781107341050.014},
  urldate = {2025-04-28},
  abstract = {Consciousness is what makes the mind-body problem really intractable. Perhaps that is why current discussions of the problem give it little attention or get it obviously wrong. The recent wave of reductionist euphoria has produced several analyses of mental phenomena and mental concepts designed to explain the possibility of some variety of materialism, psychophysical identification, or reduction. But the problems dealt with are those common to this type of reduction and other types, and what makes the mind-body problem unique, and unlike the water-H20 problem or the Turing machine-IBM machine problem or the lightning-electrical discharge problem or the gene-DNA problem or the oak tree-hydrocarbon problem, is ignored.Every reductionist has his favorite analogy from modern science. It is most unlikely that any of these unrelated examples of successful reduction will shed light on the relation of mind to brain. But philosophers share the general human weakness for explanations of what is incomprehensible in terms suited for what is familiar and well understood, though entirely different. This has led to the acceptance of implausible accounts of the mental largely because they would permit familiar kinds of reduction. I shall try to explain why the usual examples do not help us to understand the relation between mind and body-why, indeed, we have at present no conception of what an explanation of the physical nature of a mental phenomenon would be. Without consciousness the mind-body problem would be much less interesting. With consciousness it seems hopeless.},
  isbn = {978-1-107-60471-1},
  file = {/home/anhgelus/Zotero/storage/MQIF83HV/E9B3A2BE0FC6D10D3CAA3E40F7D60521.html}
}

@misc{nguyenhoangDonneesManipulentAlgorithmes2021,
  title = {Les Donn{\'e}es Manipulent Les Algorithmes},
  author = {Nguy{\^e}n Hoang, L{\^e}},
  year = {2021},
  month = apr,
  urldate = {2025-04-28}
}

@misc{nguyenhoangMillionMilliardsDilemmes2021,
  title = {Un Million de Milliards de Dilemmes},
  author = {Nguy{\^e}n Hoang, L{\^e}},
  year = {2021},
  month = mar,
  urldate = {2025-04-28}
}

@misc{nguyenhoangReseauxSociauxSont2021,
  title = {Les R{\'e}seaux Sociaux Sont Dangereux. {{Tr{\`e}s}} Dangereux.},
  author = {Nguy{\^e}n Hoang, L{\^e}},
  year = {2021},
  month = mar,
  urldate = {2025-04-28}
}

@misc{nobleCopyrightAICases2025,
  title = {Copyright and {{AI}}: The {{Cases}} and the {{Consequences}}},
  shorttitle = {Copyright and {{AI}}},
  author = {Noble, Tori},
  year = {2025},
  month = feb,
  journal = {Electronic Frontier Foundation},
  urldate = {2025-04-28},
  abstract = {The launch of ChatGPT and other deep learning quickly led to a flurry of lawsuits against model developers. Legal theories vary, but most are rooted in copyright: plaintiffs argue that use of their works to train the models was infringement; developers counter that their training is fair use....},
  howpublished = {https://www.eff.org/deeplinks/2025/02/copyright-and-ai-cases-and-consequences},
  langid = {english},
  file = {/home/anhgelus/Zotero/storage/J58EKVMZ/copyright-and-ai-cases-and-consequences.html}
}

@book{russelProblemesPhilosophiee1989,
  title = {{Probl{\`e}mes de philosophiee}},
  author = {Russel, Bertrand},
  year = {1989},
  month = feb,
  series = {{Biblioth{\`e}que philosophique}},
  edition = {Payot},
  address = {France},
  urldate = {2025-04-28},
  abstract = {Publi{\'e} en 1912, ce livre, qui marque un tournant dans l'histoire philosophique de la logique moderne, est aussi, par le souci constant qu'il manifeste d'{\'e}viter les questions trop techniques ; Par le rappel des grandes conceptions classiques que Russell passe en revue afin de mieux situer sa d{\'e}marche ; par la clart{\'e}, enfin, avec laquelle il pos},
  isbn = {978-2-228-88172-2},
  langid = {french},
  file = {/home/anhgelus/Zotero/storage/9G65576H/9782228881722-problemes-de-philosophie-bertrand-russell.html}
}

@misc{SuperBrain17Sense,
  title = {{{SuperBrain}} 1 - {{7Sense}}},
  urldate = {2025-04-28},
  howpublished = {https://7sense.ee/superbrain-1/}
}

@article{TransformeurGeneratifPreentraine2024,
  title = {{Transformeur g{\'e}n{\'e}ratif pr{\'e}entra{\^i}n{\'e}}},
  year = {2024},
  month = oct,
  journal = {Wikip{\'e}dia},
  urldate = {2025-04-28},
  abstract = {Un transformeur g{\'e}n{\'e}ratif pr{\'e}appris (ou pr{\'e}entra{\^i}n{\'e}) (ou GPT, de l'anglais generative pre-trained transformer) est un type de grand mod{\`e}le de langage bas{\'e} sur l'architecture transformeur. Le << pr{\'e}apprentissage >> consiste {\`a} pr{\'e}dire le prochain mot dans une s{\'e}quence de texte. R{\'e}p{\'e}t{\'e} pour de vastes corpus de donn{\'e}es textuelles, cet apprentissage permet ensuite au mod{\`e}le de g{\'e}n{\'e}rer du texte semblable.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {french},
  annotation = {Page Version ID: 219392366},
  file = {/home/anhgelus/Zotero/storage/XT9TUXBK/Transformeur_génératif_préentraîné.html}
}

@incollection{tulvingEpisodicMemoryAutonoesis2005,
  title = {Episodic {{Memory}} and {{Autonoesis}}: {{Uniquely Human}}?},
  shorttitle = {Episodic {{Memory}} and {{Autonoesis}}},
  booktitle = {The Missing Link in Cognition: {{Origins}} of Self-Reflective Consciousness},
  author = {Tulving, Endel},
  year = {2005},
  pages = {3--56},
  publisher = {Oxford University Press},
  address = {New York, NY, US},
  doi = {10.1093/acprof:oso/9780195161564.003.0001},
  abstract = {This chapter describes the link between episodic memory and self-reflective consciousness (or, in author Tulving's terminology, autonoetic consciousness). Autonoetic conscious is needed to allow a person to travel mentally through his or her own personal past, free of the immediate stimulus environment. Tulving also delineates the relation between this kind of episodic memory and the ability to project into the future. In Tulving's view, the latter is the kernel of consciousness that is necessary for culture. Accordingly, the evolutionary significance of the ability to think about the future and its importance for human society cannot be overestimated. Tulving also suggests a practical test, the "spoon test," as a method for determining, without the use of language, whether a person or animal possesses autonoetic consciousness. (PsycInfo Database Record (c) 2023 APA, all rights reserved)},
  isbn = {978-0-19-516156-4},
  keywords = {Consciousness States,Episodic Memory,Self-Perception}
}

@article{turingICOMPUTINGMACHINERYINTELLIGENCE1950,
  title = {I.---{{COMPUTING MACHINERY AND INTELLIGENCE}}},
  author = {Turing, A. M.},
  year = {1950},
  month = oct,
  journal = {Mind},
  volume = {LIX},
  number = {236},
  pages = {433--460},
  issn = {0026-4423},
  doi = {10.1093/mind/LIX.236.433},
  urldate = {2025-04-28},
  file = {/home/anhgelus/Zotero/storage/9JDHFYWB/986238.html}
}

@article{wellsFacebookFiles2021,
  title = {The {{Facebook Files}}},
  author = {Wells, Georgia and Horwitz, Jeff and Seetharaman, Deepa},
  year = {2021},
  month = oct,
  journal = {Wall Street Journal},
  issn = {0099-9660},
  urldate = {2025-04-28},
  abstract = {Facebook knows, in acute detail, that its platforms are riddled with flaws but hasn't fixed them. That's a key finding of a Journal series that launched this week, based on an array of internal company documents. Read all the stories here.},
  chapter = {Tech},
  langid = {american},
  keywords = {entertainment,Facebook,FB,graphics,GRAPHICS,Mark Zuckerberg,media,Media/Entertainment,online service providers,Online Service Providers,social media platforms,Social Media Platforms/Tools,SYND,technology,Technology,tools,WSJ-PRO-WSJ.com},
  file = {/home/anhgelus/Zotero/storage/VPWML2FX/the-facebook-files-11631713039.html}
}

@misc{wiktionnaireArtificiel2025,
  title = {{artificiel}},
  author = {Wiktionnaire},
  year = {2025},
  month = feb,
  journal = {Wiktionnaire},
  publisher = {Wikipedia},
  urldate = {2025-04-28},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {french},
  annotation = {Page Version ID: 37389762},
  file = {/home/anhgelus/Zotero/storage/MAW6X577/artificiel.html}
}

@misc{wiktionnaireConscience2025,
  title = {{conscience}},
  author = {Wiktionnaire},
  year = {2025},
  month = apr,
  journal = {Wiktionnaire},
  publisher = {Wikipedia},
  urldate = {2025-04-28},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {french},
  annotation = {Page Version ID: 38065068},
  file = {/home/anhgelus/Zotero/storage/G59RWHKY/conscience.html}
}
